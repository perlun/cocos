MemoryMap.txt ($Id$)
=============

This is the memory map/general VM theory for the cocOS architecture, sometimes referred to as "The cocOS VM Specification".

General Concept and IA32 Background
-----------------------------------

Virtual Memory is a concept introduced (when speaking about the Intel line of CPU:s) with the 80386. In the 80386 (IA32)
architecture, it is also called "paging". The memory is divided into physical "pages", normally with a size of 4096
bytes. There is also a concept of "huge pages", which are 4 MiB large in the usual 80386 scenario.

With the 80386 architecture, the Virtual Memory space is limited by the 32-bit addressing. Virtual Memory is addressed just
like physical memory; in other words, using 32 address lines. This means that 4 GiB of physical memory can be adressed, and 4
GiB of virtual memory *per process*.

This latter statement is important. Since each process ("task" in Intel speak) can have its own memory map being set up
(using per-task differentiated values for the CR3 register), each process can have a virtual memory space of up to 4 GiB
which does not necessarily have to be identical to the virtual memory space of another process.

This can be useful sometimes, with memory mapped files for example. But obviously, the 4 GiB physical/virtual limit can be
limiting at times. Large RDBMS for example (relational database management systems), can pretty easily run into situations
where you have a database that is larger than 4 GiB. Those databases can only be memory-mapped if the virtual memory limit is
*larger* than the physical memory limit.

There is also another problem with the 4 GiB virtual memory limit, namely this: For the kernel to be able to access the
memory that belongs all the processes in the system (for example, if/when performing message-based IPC), it is highly
convenient for the kernel to have all the physical memory being mapped in the virtual memory space. One way to do it is to
"split" the virtual memory in two halves: 0-2 GiB is reserved for user programs, and 2-4 GiB is reserved for the kernel.

There is only one "small" caveat with this. By doing so, you effectively limit the maximum memory size of the system to 2
GiB, which is fairly small by todays standards.

Both of these problems, which have the same general cause -- the virtual memory space is too little on the IA32 -- are solved
by the x86-64 (hereafter referred to as the "AMD64" architecture).

The AMD64 Architecture
----------------------

In the AMD64 architecture, those limits are raised. But not (yet) to the full 64-bit that one could expect. Instead, AMD (and
Intel) has taken a more pragmatic approach, which probably wise since 64 full address lines would be a total waste of money
(in producing the chips) and circuit space (in the CPU die). The physical and virtual address sizes are more "floating" than
before. The machine that I am currently writing this text on has 36 physical address lines (allowing systems to access up to
64 GiB of RAM, pretty much by the standards of this very day). The good thing about it, though, is that it has 48 virtual
address lines. This means that there is no problem to have a *bunch* of programs mapping, say 10 GiB of virtual memory
each. And the best thing of it all is that in the end, this 48-bit limit will be increased upwards, as a need arises.

When the address space is limited to 48 bits, AMD has invented something called a "sign extension". This means that in the
machines with 48 bits virtual addressing, bit 48-63 must be copies of bit 47.

This means that in effect, there is a memory "hole", like this:

00000000 00000000-00007FFF FFFFFFFF (Canonical "lower half", 128 TiB, terabyte)
FFFF8000 00000000-FFFFFFFF FFFFFFFF (Canonical "upper half", 128 TiB)

Now that we have the baseline set, we can go on to the cocOS-specific memory map.

High-level Mappings
-------------------

* Physical VM (0-128 TiB). For convenience, the physical VM is "identity mapped". This means that to access memory at address
  0xB8000, you create a pointer that points at 0xB8000 -- simple and beautiful. Demo/intro and other lowlevel/assembly coders
  will love it! :-) Really, mapping this memory with a straight 1-to-1 mapping, where any physical memory address can be 
  accessed in a really intuitive and simple way must be the best thinkable way to do it, in my imagination.

* Process VM ("upper half", the very last 128 TiB of the 64-bit virtual address space). This memory is reserved for use by
  processes. This means that the .code section (as well as any other section) of a 64-bit ELF binary for cocOS must be within
  this range. The ELF loader should (and will) check these ranges when creating the process, and return an error value if
  the ELF specifies invalid section addresses.

Low-level Mappings
------------------

* The physical VM is mapped 1-to-1, using 2 MiB (also known as "large" or "huge") pages. The only exception to this is the
  very first 2 MiB of RAM. Because of the possibility of NULL pointers that can occur in the C and C++ programming
  languages, among others, we need to make memory address 0x0 be something "unmapped", not referring to anything. If we do
  so, we will get a "page fault" exception -- which the kernel then can trap and handle in a correct and deterministic way.
  If we would *not* do it like this, kernel NULL pointers could never be trapped, which could lead to pretty hard-to-catch
  bugs within the kernel.

* The first 2 MiB is mapped like this:
  - Page Map Level 4 index 0 (first page directory)
    # Page Directory index 0 (first page table):
      1) Page 0 (0-4 KiB): Not mapped. We achieve this by setting the P (Present) flag to zero. This means an exception will
         occur on every attempt to read or write from this memory.
      2) Page 1-511 (4 KiB-2 MiB): Mapped using 4 KiB pages.
    # Page Directory index 1 (second page table):
      1) Page 0 (2-4 MiB): Identity-mapped. In other words, matches physical memory address 2-4 MiB.
      2) Page 1 (4-6 MiB): Identity-mapped.
        ...
      3) Page 511 (1024-1026 MiB). Identity-mapped.
    # Page Directory index 2 (third page table)
      1) Similar pattern as for Page Directory index 2. At startup, we detect the amount of physical memory available and only
         map up to the amount of memory available. The rest of the PDPE:s in that page directory will have a base address of
         zero and the present flag being cleared. The AVL bits will also be set to 111, to indicate that this memory is
         not available in the machine.
  - Page Map Level 4 index 0(second page directory)
    # One page director can hold information 

Physical Memory Structure
-------------------------
Please note that these areas are "zones" rather than actual usage. If only 16 KiB of paging structures are needed, only
16 KiB will be allocated. But because of the inheritant complexity of a kernel physical/virtual memory subsystem, having
these a bit fixed simplifies things a lot; it makes it possible to do some assumptions.

- 0-512 KiB: reserved for paging structures.
- 1-2 MiB: reserved for kernel memory.
- 2 MiB-as much as is needed: reserved for paging structures.

The "paging structures" here are only referring to the paging structures used for holding information about physical memory
mappings (1-1 identity mapped pages). Regular user process mappings don't need to be kept as fixed locations like those;
memory for those pages can be allocated by the kernel through the process page allocator, or similar.

Paging Structures Memory Requirements
-------------------------------------
When speaking below about the memory requirements for the paging structures, we are only taking about the structures used for
mapping physical memory. Process-based virtual memory allocation will require additional structures.

- PML4: always present (1 page). Covers virtual memory up to 2^48 bytes.
- PDP: covers virtual memory up to 2^39 bytes (1 page per 2^39 block), or 512 gigs of RAM.
- PD: one table per gigabyte of RAM (2^30 bytes).
- PT: not used with 2 MiB pages. When using 4 KiB pages, one per 2 MiB. Since we map memory 0-2 MiB using 4 KiB pages, we 
  need one of those. (One page table

So, some practical examples:
- 1 GiB of RAM: 1 + 1 + 1 + 1 = 4 pages à 4 KiB each = 4 * 4 = 16 KiB.
- 8 GiB of RAM: 1 + 1 + 8 + 1 = 11 pages à 4 KiB each = 44 KiB.
...
- 125 GiB of RAM: 1 + 1 + 125 + 1 = 128 pages à 4 KiB each = 512 KiB. With the current placement of the paging structures,
  this is beginning to approach the limit. The VMWare in which I am running my development has a memory hole starting at
  around 580 KiB, or something like that.  For the current time being, this memory limit seems pretty OK to me... We could
  always locate extra page directories in another place; the only problem with it is that it needs to be a pretty "fixed"
  spot because of the always recurring "chicken-and-egg" problem with kernel memory allocation (the VM system needs memory
  allocation which needs VM...). As listed about, my idea is that after 512 KiB, we place potential extra page tables from 2
  MiB and upwards.  What this means in reality is that kernel code + static data cannot exceed 1 megabyte in size. This
  shouldn't really be a problem, ever; if it does, we have lost the initial scope quite a bit IMO.

  For the time being though, we only implement support for up to 125 GiB of RAM, which should be enough for everybody^Wa
  while...

-- Per Lundberg <per@halleluja.nu>  Mon,  3 Nov 2008 20:58:39 +0200
